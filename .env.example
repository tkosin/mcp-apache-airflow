# ==========================================
# Apache Airflow with MCP Server Configuration
# ==========================================
# Copy this file to .env and update with your values
# cp .env.example .env

# ==========================================
# Airflow Core Configuration
# ==========================================

# User ID for Airflow processes (should match your system user ID)
# Run: echo $(id -u) to get your UID
AIRFLOW_UID=50000
AIRFLOW_GID=0

# Airflow and Python versions
AIRFLOW_VERSION=2.10.4
PYTHON_VERSION=3.13

# ==========================================
# Airflow Core Settings
# ==========================================

# Executor type: LocalExecutor, CeleryExecutor, KubernetesExecutor
AIRFLOW__CORE__EXECUTOR=CeleryExecutor

# Load example DAGs (False for production)
AIRFLOW__CORE__LOAD_EXAMPLES=False

# Fernet key for encrypting connections and variables
# Generate new key with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW__CORE__FERNET_KEY=CHANGE_THIS_TO_A_RANDOM_FERNET_KEY

# Secret key for Flask sessions
# Generate with: openssl rand -hex 32
AIRFLOW__WEBSERVER__SECRET_KEY=CHANGE_THIS_TO_A_RANDOM_SECRET_KEY

# ==========================================
# Database Configuration (PostgreSQL)
# ==========================================

# PostgreSQL credentials
POSTGRES_USER=airflow
POSTGRES_PASSWORD=CHANGE_THIS_PASSWORD_IN_PRODUCTION
POSTGRES_DB=airflow
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# SQLAlchemy connection string
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:CHANGE_THIS_PASSWORD_IN_PRODUCTION@postgres:5432/airflow

# ==========================================
# Redis Configuration (Celery Broker)
# ==========================================

# Redis connection details
REDIS_HOST=redis
REDIS_PORT=6379

# Celery broker and result backend URLs
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:CHANGE_THIS_PASSWORD_IN_PRODUCTION@postgres:5432/airflow

# ==========================================
# Airflow API Configuration
# ==========================================

# Authentication backend for REST API
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth

# Enable experimental API endpoints (use with caution in production)
AIRFLOW__API__ENABLE_EXPERIMENTAL_API=True

# ==========================================
# Airflow Admin User (Created on Initialization)
# ==========================================

# Default admin user credentials
# IMPORTANT: Change these for production!
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=CHANGE_THIS_ADMIN_PASSWORD
_AIRFLOW_WWW_USER_FIRSTNAME=Admin
_AIRFLOW_WWW_USER_LASTNAME=User
_AIRFLOW_WWW_USER_EMAIL=admin@example.com
_AIRFLOW_WWW_USER_ROLE=Admin

# ==========================================
# MCP Server Configuration
# ==========================================

# MCP Server network settings
MCP_SERVER_PORT=3000
MCP_SERVER_HOST=0.0.0.0

# Airflow connection for MCP Server
# Note: Use localhost:8080 when accessing from host machine
# Use airflow-webserver:8080 when accessing from within Docker network
AIRFLOW_BASE_URL=http://airflow-webserver:8080

# MCP Server authentication (should match admin user above)
AIRFLOW_API_USERNAME=admin
AIRFLOW_API_PASSWORD=CHANGE_THIS_ADMIN_PASSWORD

# ==========================================
# Optional: Advanced Settings
# ==========================================

# Timezone for Airflow (default: UTC)
# Examples: UTC, America/New_York, Europe/London, Asia/Bangkok
AIRFLOW__CORE__DEFAULT_TIMEZONE=UTC

# Project directory (usually current directory)
# AIRFLOW_PROJ_DIR=.

# ==========================================
# Security Notes
# ==========================================
# 1. NEVER commit the actual .env file to version control
# 2. Change all passwords and secret keys in production
# 3. Use strong, randomly generated values for:
#    - AIRFLOW__CORE__FERNET_KEY
#    - AIRFLOW__WEBSERVER__SECRET_KEY
#    - POSTGRES_PASSWORD
#    - _AIRFLOW_WWW_USER_PASSWORD
# 4. Consider using Docker secrets or a secrets manager in production
